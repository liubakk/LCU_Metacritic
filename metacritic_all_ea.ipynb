{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598858495251",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--- 25.381119966506958 seconds ---\n"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# OPTIMIZATION : Calculating the start time\n",
    "start_time = time.time()\n",
    "\n",
    "#Dictionary for titles urls scraping\n",
    "title_url_dict= {'title':[]}\n",
    "\n",
    "#Generating the title list from the 'Electronic Arts' page on metacritic\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "url = 'https://www.metacritic.com/company/electronic-arts'\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#current page cout 58 (30 items per page)\n",
    "page_count = int(soup.find('li', class_='page last_page').find('a').text)\n",
    "\n",
    "for page in range (0,page_count):\n",
    "        url = 'https://www.metacritic.com/company/electronic-arts?page='+str(page)\n",
    "        response  = requests.get(url, headers = user_agent)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for title in soup.find_all('td', class_='title brief_metascore'):\n",
    "                if title.find('a') == None:\n",
    "                        break\n",
    "                # CLEANUP: Removing mobile titles\n",
    "                if '/ios/' not in title.find('a')['href']:\n",
    "                        title_url_dict['title'].append(title.find('a')['href'])\n",
    "        \n",
    "        # PROGRESSLINE : % of pages processed - printed in the output bar\n",
    "        clear_output()\n",
    "        print(\"Progress: {:2.1%}\".format(page / page_count))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "#converting the dictionary to a dataframe\n",
    "title_url_df = pd.DataFrame(title_url_dict)\n",
    "\n",
    "#generating the titles urls array \n",
    "title_url_list = title_url_df['title'].to_numpy()\n",
    "\n",
    "#generating the platforms and titles names arrays\n",
    "title_url_df = title_url_df.title.str.split(\"/\",expand=True,)\n",
    "platforms = title_url_df[2].to_numpy()\n",
    "titles = title_url_df[3].to_numpy()\n",
    "\n",
    "# PROGRESSLINE : Completed - printed in the output bar\n",
    "clear_output()\n",
    "#print(\"Complete!\")\n",
    "\n",
    "# OPTIMIZATION : Calculating the time elapsed\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--- 1667.2636439800262 seconds ---\n"
    }
   ],
   "source": [
    "# OPTIMIZATION : Calculating the start time\n",
    "start_time = time.time()\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "#Dictionary for titles info scraping\n",
    "ea_title_dict = {'date':[], 'title_url':[], 'title_name':[], 'platform':[],'title_genres':[], 'release_date':[],\n",
    "                'metascore':[], 'critic_reviews_count':[],'pos_critic_reviews_count':[],'mix_critic_reviews_count':[],'neg_critic_reviews_count':[],\n",
    "                'agv_user_score':[], 'user_ratings_count':[],'pos_user_reviews_count':[],'mix_user_reviews_count':[],'neg_user_reviews_count':[]}\n",
    "\n",
    "#Iterating through the list of titles to scrape the info\n",
    "for i in range(0,len(title_url_list)):\n",
    "        \n",
    "        url = 'https://www.metacritic.com' + title_url_list[i]\n",
    "        response  = requests.get(url, headers = user_agent)\n",
    "        \n",
    "        # Checking that the page exists\n",
    "        if response.status_code == 200: \n",
    "           \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            url_base = title_url_list[i]\n",
    "            \n",
    "            # CLEANUP - Removing titles with no metacritic score or Canceled\n",
    "            critic_score = soup.find('a', class_='metascore_anchor', href=url_base+'/critic-reviews')\n",
    "            release_date = soup.find('li', class_='summary_detail release_data').find('span', class_='data').text\n",
    "\n",
    "            if critic_score != None and release_date != 'Canceled':\n",
    "\n",
    "                # Today's date, title url, title name, platform & metascore\n",
    "                Today_Date = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "                ea_title_dict['date'].append(Today_Date)\n",
    "                ea_title_dict['title_url'].append(title_url_list[i])\n",
    "                ea_title_dict['title_name'].append(titles[i])\n",
    "                ea_title_dict['platform'].append(platforms[i])\n",
    "                ea_title_dict['metascore'].append(int(critic_score.find('span').text))\n",
    "        \n",
    "                #average user score\n",
    "                agv_user_score = soup.find('a', class_='metascore_anchor', href=url_base+'/user-reviews')\n",
    "                if agv_user_score == None or agv_user_score.find('div').text == 'tbd':\n",
    "                    ea_title_dict['agv_user_score'].append(float(0))\n",
    "                else:\n",
    "                    ea_title_dict['agv_user_score'].append(float(agv_user_score.find('div').text))\n",
    "                \n",
    "                #release_date\n",
    "                release_date = soup.find('li', class_='summary_detail release_data')\n",
    "                if release_date == None:\n",
    "                    ea_title_dict['release_date'].append(float(0))\n",
    "                else:\n",
    "                    #exporting the date in the datetime format or keeping the original format for dates that do not fit the format\n",
    "                    try :\n",
    "                        # Date Format 'Oct 13, 2020'\n",
    "                        release_date = datetime.strptime(release_date.find('span', class_='data').text,'%b %d, %Y')\n",
    "                        ea_title_dict['release_date'].append(release_date)\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Date Format '2020'\n",
    "                            release_date = datetime.strptime(release_date.find('span', class_='data').text,'%Y')\n",
    "                            ea_title_dict['release_date'].append(release_date)\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                # Date Format 'September 2020'\n",
    "                                release_date = datetime.strptime(release_date.find('span', class_='data').text,'%B %Y')\n",
    "                                ea_title_dict['release_date'].append(release_date)\n",
    "                            except ValueError:\n",
    "                                # Other Date Formats stored as text\n",
    "                                ea_title_dict['release_date'].append(release_date.find('span', class_='data').text)\n",
    "            \n",
    "                #List of genres separated by comma\n",
    "                title_genres_text = ''\n",
    "\n",
    "                # CLEANUP - Reducing the number of genres to 18 (as defined by Metacritic) + Miscellaneous \n",
    "                title_genres_list = ['Action','Adventure','Action Adventure','Fighting','First-Person','Flight','Party','Platformer','Puzzle',\n",
    "                                    'Racing','Real-Time','Role-Playing','Simulation','Sports','Strategy','Third-Person','Turn-Based','Wargames','Wrestling','Miscellaneous']\n",
    "\n",
    "                title_genres = soup.find('li', class_='summary_detail product_genre')\n",
    "                \n",
    "                if title_genres == None:\n",
    "                    ea_title_dict['title_genres'].append('')\n",
    "                else:\n",
    "                    for genre in title_genres.find_all('span', class_='data'):\n",
    "                            # CLEANUP - Removing duplicated genre names\n",
    "                            if genre.text in title_genres_list and genre.text not in title_genres_text:\n",
    "                                if title_genres_text == '':\n",
    "                                    title_genres_text = title_genres_text+genre.text\n",
    "                                else:\n",
    "                                    title_genres_text = title_genres_text+','+genre.text\n",
    "                    if title_genres_text == '':\n",
    "                        ea_title_dict['title_genres'].append('Miscellaneous')\n",
    "                    else:\n",
    "                        ea_title_dict['title_genres'].append(title_genres_text)\n",
    "\n",
    "                #number of critic reviews and number of user reviews\n",
    "                critic_reviews = 0\n",
    "                user_reviews = 0\n",
    "\n",
    "                for summary in soup.find_all('div', class_='summary'):\n",
    "                        if summary.find('a', href=url_base+'/critic-reviews') != None:\n",
    "                            critic_reviews = summary.find('a', href=url_base+'/critic-reviews').find('span').text\n",
    "                            ea_title_dict['critic_reviews_count'].append(int(critic_reviews))\n",
    "                        \n",
    "                        if summary.find('a', href=url_base+'/user-reviews') != None:\n",
    "                            user_reviews = summary.find('a', href=url_base+'/user-reviews').text\n",
    "                            ea_title_dict['user_ratings_count'].append(int(user_reviews.replace(' Ratings','')))\n",
    "\n",
    "                if critic_reviews == 0:\n",
    "                            ea_title_dict['critic_reviews_count'].append(int(0))\n",
    "                if user_reviews == 0:\n",
    "                            ea_title_dict['user_ratings_count'].append(int(0))\n",
    "            \n",
    "                url_base_count = url_base +'/critic-reviews?dist='\n",
    "\n",
    "                #number of positive critic reviews\n",
    "                pos_critic_reviews_count = soup.find('a', href=url_base_count+'positive')\n",
    "                if pos_critic_reviews_count == None:\n",
    "                    ea_title_dict['pos_critic_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['pos_critic_reviews_count'].append(int(pos_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "                \n",
    "                #number of neutral critic reviews\n",
    "                mix_critic_reviews_count = soup.find('a', href=url_base_count+'neutral')\n",
    "                if mix_critic_reviews_count == None:\n",
    "                    ea_title_dict['mix_critic_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['mix_critic_reviews_count'].append(int(mix_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "                \n",
    "                #number of negative critic reviews\n",
    "                neg_critic_reviews_count = soup.find('a', href=url_base_count+'negative')\n",
    "                if neg_critic_reviews_count == None:\n",
    "                    ea_title_dict['neg_critic_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['neg_critic_reviews_count'].append(int(neg_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "            \n",
    "                url_base_count = url_base +'/user-reviews?dist='\n",
    "                \n",
    "                #number of positive user reviews\n",
    "                pos_user_reviews_count = soup.find('a', href=url_base_count+'positive')\n",
    "                if pos_user_reviews_count == None:\n",
    "                    ea_title_dict['pos_user_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['pos_user_reviews_count'].append(int(pos_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "                \n",
    "                #number of neutral user reviews\n",
    "                mix_user_reviews_count = soup.find('a', href=url_base_count+'neutral')\n",
    "                if mix_user_reviews_count == None:\n",
    "                    ea_title_dict['mix_user_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['mix_user_reviews_count'].append(int(mix_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "                \n",
    "                #number of negative user reviews\n",
    "                neg_user_reviews_count = soup.find('a', href=url_base_count+'negative')\n",
    "                if neg_user_reviews_count == None:\n",
    "                    ea_title_dict['neg_user_reviews_count'].append(int(0))\n",
    "                else:\n",
    "                    ea_title_dict['neg_user_reviews_count'].append(int(neg_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "\n",
    "            # Progress - % of titles processed - printed in the output bar\n",
    "            clear_output()\n",
    "            print(\"Progress: {:2.1%}\".format(i / len(title_url_list))+\" \")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "# Progress - Completed - printed in the output bar\n",
    "clear_output()\n",
    "#print(\"Complete!\")\n",
    "\n",
    "# OPTIMIZATION : Calculating the time elapsed\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dictionary into the dataframe\n",
    "ea_title_df = pd.DataFrame(ea_title_dict, columns = ['date', 'title_url', 'title_name', 'platform','title_genres', 'release_date',\n",
    "                                     'metascore', 'critic_reviews_count','pos_critic_reviews_count','mix_critic_reviews_count','neg_critic_reviews_count',\n",
    "                                     'agv_user_score', 'user_ratings_count', 'pos_user_reviews_count','mix_user_reviews_count','neg_user_reviews_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up the data frame\n",
    "ea_title_df.drop(ea_title_df[ea_title_df.release_date == 'Canceled'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the the dataframe into an excel file with the date and time in the title\n",
    "Date_Time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "excelfilename = 'ea_metacritic_'+Date_Time +\".xlsx\"\n",
    "ea_title_df.to_excel (r'/Users/liuba/Desktop/files/'+excelfilename, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}