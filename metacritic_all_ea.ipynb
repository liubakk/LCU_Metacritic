{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598858495251",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Complete!\n"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#dictionary for titles urls scraping\n",
    "title_url_dict= {'title':[]}\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "#Generating the title list from the 'electronic arts' page on metacritic\n",
    "#current page cout 58 (30 items per page)\n",
    "url = 'https://www.metacritic.com/company/electronic-arts'\n",
    "response  = requests.get(url, headers = user_agent)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "page_count = int(soup.find('li', class_='page last_page').find('a').text)\n",
    "\n",
    "for page in range (0,page_count):\n",
    "        url = 'https://www.metacritic.com/company/electronic-arts?page='+str(page)\n",
    "        response  = requests.get(url, headers = user_agent)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for title in soup.find_all('td', class_='title brief_metascore'):\n",
    "                if title.find('a') == None:\n",
    "                        break \n",
    "                if 'ios' not in title.find('a')['href']: # excluding mobile titles\n",
    "                        title_url_dict['title'].append(title.find('a')['href'])\n",
    "        \n",
    "        # Progress - % of pages processed - printed in the output bar\n",
    "        clear_output()\n",
    "        print(\"Progress: {:2.1%}\".format(page / page_count))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "#converting the dictionary to a dataframe\n",
    "title_url_df = pd.DataFrame(title_url_dict)\n",
    "\n",
    "#generating the titles urls array \n",
    "title_url_list = title_url_df['title'].to_numpy()\n",
    "\n",
    "#generating the platforms and titles names arrays\n",
    "title_url_df = title_url_df.title.str.split(\"/\",expand=True,)\n",
    "platforms = title_url_df[2].to_numpy()\n",
    "titles = title_url_df[3].to_numpy()\n",
    "\n",
    "# Progress - Completed - printed in the output bar\n",
    "clear_output()\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Complete!\n"
    }
   ],
   "source": [
    "#dictionary for titles info scraping\n",
    "ea_title_dict = {'date':[], 'title_url':[], 'title_name':[], 'platform':[],'title_genres':[], 'release_date':[], 'metascore':[], 'critic_reviews_count':[],'pos_critic_reviews_count':[],'mix_critic_reviews_count':[],'neg_critic_reviews_count':[], 'agv_user_score':[], 'user_ratings_count':[],'pos_user_reviews_count':[],'mix_user_reviews_count':[],'neg_user_reviews_count':[]}\n",
    "\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "#Iterating throug the list of titles to scrape the info\n",
    "for i in range(0,len(title_url_list)):\n",
    "        \n",
    "        #date\n",
    "        Today_Date = time.strftime(\"%Y%m%d\")\n",
    "        ea_title_dict['date'].append(Today_Date)\n",
    "\n",
    "        url = 'https://www.metacritic.com' + title_url_list[i]\n",
    "        response  = requests.get(url, headers = user_agent)\n",
    "        \n",
    "        if response.status_code == 200: #if the page exists\n",
    "\n",
    "            #title id, name and platform\n",
    "            ea_title_dict['title_url'].append(title_url_list[i])\n",
    "            ea_title_dict['title_name'].append(titles[i])\n",
    "            ea_title_dict['platform'].append(platforms[i])\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            url_base = title_url_list[i]\n",
    "            \n",
    "            #metascore\n",
    "            critic_score = soup.find('a', class_='metascore_anchor', href=url_base+'/critic-reviews')\n",
    "            if critic_score == None:\n",
    "                ea_title_dict['metascore'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['metascore'].append(int(critic_score.find('span').text))\n",
    "        \n",
    "            #average user score\n",
    "            agv_user_score = soup.find('a', class_='metascore_anchor', href=url_base+'/user-reviews')\n",
    "            if agv_user_score == None or agv_user_score.find('div').text == 'tbd':\n",
    "                ea_title_dict['agv_user_score'].append(float(0))\n",
    "            else:\n",
    "                ea_title_dict['agv_user_score'].append(float(agv_user_score.find('div').text))\n",
    "            \n",
    "            #release_date\n",
    "            release_date = soup.find('li', class_='summary_detail release_data')\n",
    "            if release_date == None:\n",
    "                ea_title_dict['release_date'].append(float(0))\n",
    "            else:\n",
    "                #exporting the date in the datetime format or keeping the original format for dates that do not fit the format\n",
    "                try :\n",
    "                    datetime.strptime(release_date.find('span', class_='data').text,'%b %d, %Y')\n",
    "                    release_date = datetime.strptime(release_date.find('span', class_='data').text,'%b %d, %Y')\n",
    "                    ea_title_dict['release_date'].append(release_date)\n",
    "                except ValueError:\n",
    "                    ea_title_dict['release_date'].append(release_date.find('span', class_='data').text)\n",
    "            \n",
    "            #genres\n",
    "            title_genres_text = ''\n",
    "            title_genres = soup.find('li', class_='summary_detail product_genre')\n",
    "            if title_genres == None:\n",
    "                ea_title_dict['title_genres'].append('')\n",
    "            else:\n",
    "                for genre in title_genres.find_all('span', class_='data'):\n",
    "                        if title_genres_text == '':\n",
    "                            title_genres_text = title_genres_text+genre.text\n",
    "                        else:\n",
    "                            title_genres_text = title_genres_text+', '+genre.text\n",
    "                ea_title_dict['title_genres'].append(title_genres_text)\n",
    "\n",
    "            #number of critic reviews and number of user reviews\n",
    "            critic_reviews = 0\n",
    "            user_reviews = 0\n",
    "            for summary in soup.find_all('div', class_='summary'):\n",
    "                    \n",
    "                    if summary.find('a', href=url_base+'/critic-reviews') != None:\n",
    "                        critic_reviews = summary.find('a', href=url_base+'/critic-reviews').find('span').text\n",
    "                        ea_title_dict['critic_reviews_count'].append(int(summary.find('a', href=url_base+'/critic-reviews').find('span').text))\n",
    "                    \n",
    "                    if summary.find('a', href=url_base+'/user-reviews') != None:\n",
    "                        user_reviews = summary.find('a', href=url_base+'/user-reviews').text\n",
    "                        ea_title_dict['user_ratings_count'].append(int(summary.find('a', href=url_base+'/user-reviews').text.replace(' Ratings','')))       \n",
    "            if critic_reviews == 0:\n",
    "                        ea_title_dict['critic_reviews_count'].append(int(0))\n",
    "            if user_reviews == 0:\n",
    "                        ea_title_dict['user_ratings_count'].append(int(0))\n",
    "\n",
    "            \n",
    "            url_base_count = url_base +'/critic-reviews?dist='\n",
    "\n",
    "            #number of positive critic reviews\n",
    "            pos_critic_reviews_count = soup.find('a', href=url_base_count+'positive')\n",
    "            if pos_critic_reviews_count == None:\n",
    "                ea_title_dict['pos_critic_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['pos_critic_reviews_count'].append(int(pos_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "            \n",
    "            #number of neutral critic reviews\n",
    "            mix_critic_reviews_count = soup.find('a', href=url_base_count+'neutral')\n",
    "            if mix_critic_reviews_count == None:\n",
    "                ea_title_dict['mix_critic_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['mix_critic_reviews_count'].append(int(mix_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "            \n",
    "            #number of negative critic reviews\n",
    "            neg_critic_reviews_count = soup.find('a', href=url_base_count+'negative')\n",
    "            if neg_critic_reviews_count == None:\n",
    "                ea_title_dict['neg_critic_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['neg_critic_reviews_count'].append(int(neg_critic_reviews_count.find('span', class_=\"count\").text))\n",
    "            \n",
    "            \n",
    "            url_base_count = url_base +'/user-reviews?dist='\n",
    "            \n",
    "            #number of positive user reviews\n",
    "            pos_user_reviews_count = soup.find('a', href=url_base_count+'positive')\n",
    "            if pos_user_reviews_count == None:\n",
    "                ea_title_dict['pos_user_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['pos_user_reviews_count'].append(int(pos_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "            \n",
    "            #number of neutral user reviews\n",
    "            mix_user_reviews_count = soup.find('a', href=url_base_count+'neutral')\n",
    "            if mix_user_reviews_count == None:\n",
    "                ea_title_dict['mix_user_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['mix_user_reviews_count'].append(int(mix_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "            \n",
    "            #number of negative user reviews\n",
    "            neg_user_reviews_count = soup.find('a', href=url_base_count+'negative')\n",
    "            if neg_user_reviews_count == None:\n",
    "                ea_title_dict['neg_user_reviews_count'].append(int(0))\n",
    "            else:\n",
    "                ea_title_dict['neg_user_reviews_count'].append(int(neg_user_reviews_count.find('span', class_=\"count\").text.replace(',','')))\n",
    "\n",
    "        # Progress - % of titles processed - printed in the output bar\n",
    "        clear_output()\n",
    "        print(\"Progress: {:2.1%}\".format(i / len(title_url_list))+\" \")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "#Converting the dictionary into tha dataframe\n",
    "ea_title_df = pd.DataFrame(ea_title_dict, columns = ['date', 'title_url', 'title_name', 'platform','title_genres', 'release_date', 'metascore', 'critic_reviews_count','pos_critic_reviews_count','mix_critic_reviews_count','neg_critic_reviews_count', 'agv_user_score', 'user_ratings_count', 'pos_user_reviews_count','mix_user_reviews_count','neg_user_reviews_count'])\n",
    "\n",
    "# Progress - Completed - printed in the output bar\n",
    "clear_output()\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the the dataframe into an excel file with the date and time in the title\n",
    "Date_Time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "excelfilename = 'ea_metacritic_'+Date_Time +\".xlsx\"\n",
    "ea_title_df.to_excel (r'/Users/liuba/Desktop/files/'+excelfilename, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}